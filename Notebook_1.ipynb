{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Notebook_1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNesd6FJEWgaxIzDj45uISn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leonardoLavagna/PyTorch-Notebooks/blob/main/Notebook_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PyTorch Notebook 1\n",
        "## Fundamentals\n",
        "In this first notebook we will start familiarizing with PyTorch and its fundamentals."
      ],
      "metadata": {
        "id": "kI4asVW14LZQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "rEuFkKPN5u5I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# GPU Info (in Google Colab)\n",
        "# !nvidia-smi"
      ],
      "metadata": {
        "id": "qkQQKKYx4QJd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oevjohsa4fhc",
        "outputId": "4b703da9-26cf-47a1-df1e-2ffbc43462e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.12.1+cu113\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tensors\n",
        "Tensors are the main buildin blocks of deep learning. In particular tensors are used to represent (numerical) data in PyTorch. There are many types of tensors with different dimensions (e.g. scalars, vectors, matrixes,...) and they are usually created using `torch.tensor()` (see https://pytorch.org/docs/stable/tensors.html)."
      ],
      "metadata": {
        "id": "hQxmUsj35mSW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an empty tensor (scalar)\n",
        "# Remark . An empty tensor is usually not initialized.\n",
        "x = torch.empty(1)\n",
        "print(x)\n",
        "# For a scalar tensor x we can get the tensor value with x.item()\n",
        "print(x.item())\n",
        "# default type\n",
        "print(x.dtype)\n",
        "# dimension and shape\n",
        "print(x.ndim)\n",
        "print(x.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8iWdyN65tET",
        "outputId": "917dc57a-9b10-49b2-b900-a1fe76625628"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1.0148e-35])\n",
            "1.0147546818969555e-35\n",
            "torch.float32\n",
            "1\n",
            "torch.Size([1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a specific tensor (scalar) with a different data type\n",
        "x = torch.tensor(1,dtype=torch.int32)\n",
        "print(x)\n",
        "print(x.item())\n",
        "print(x.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uks1A6Xs6cOm",
        "outputId": "0c43019a-52a8-4f45-dad1-51b235d6ee5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1, dtype=torch.int32)\n",
            "1\n",
            "torch.int32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Remark .** The default datatype of a tensor is `float32`. This can be changed in many other data types: `int32, float16, complex 64`... see https://pytorch.org/docs/stable/tensors.html for all the data types available. "
      ],
      "metadata": {
        "id": "YqdRChxlEYbH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a vector with all zeros\n",
        "x = torch.zeros(2)\n",
        "print(x)\n",
        "print(x.ndim)\n",
        "print(x.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NwywuXc_7VLE",
        "outputId": "21dcf7d8-2ead-44d4-a84c-d7d106d47ae9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0., 0.])\n",
            "1\n",
            "torch.Size([2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a 2x2 matrix with all ones\n",
        "x = torch.ones(2,2)\n",
        "print(x)\n",
        "print(x.ndim)\n",
        "print(x.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SG8sifWZ9Zfi",
        "outputId": "891e2862-00b2-4b2a-e520-0df08352a3c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1.],\n",
            "        [1., 1.]])\n",
            "2\n",
            "torch.Size([2, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Access elements\n",
        "print(x[1])\n",
        "print(x[1][1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jWlwBNB9n1x",
        "outputId": "4819060d-dcd0-41b1-d15d-3b488a597c23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 1.])\n",
            "tensor(1.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tensor (1 tensor 2x3)\n",
        "x = torch.tensor([[[1,2,3],[4,5,6]]])\n",
        "print(x)\n",
        "print(x.ndim)\n",
        "print(x.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZKvYPUVM91bs",
        "outputId": "8a35cc1a-2287-45b9-d442-e69882413ec5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[1, 2, 3],\n",
            "         [4, 5, 6]]])\n",
            "3\n",
            "torch.Size([1, 2, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a random tensor\n",
        "# Random seed (for this block)\n",
        "random_seed = 1234\n",
        "torch.manual_seed(random_seed)\n",
        "# Random tensor\n",
        "x = torch.rand(1,2,3,3)\n",
        "print(x)\n",
        "print(x.ndim)\n",
        "print(x.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x8HvP0pa-KWZ",
        "outputId": "72814f4f-75ee-4218-dbe5-510dde436799"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[[0.0290, 0.4019, 0.2598],\n",
            "          [0.3666, 0.0583, 0.7006],\n",
            "          [0.0518, 0.4681, 0.6738]],\n",
            "\n",
            "         [[0.3315, 0.7837, 0.5631],\n",
            "          [0.7749, 0.8208, 0.2793],\n",
            "          [0.6817, 0.2837, 0.6567]]]])\n",
            "4\n",
            "torch.Size([1, 2, 3, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Access elements\n",
        "print(x[0])\n",
        "print(x[0][0])\n",
        "print(x[0][0][0])\n",
        "print(x[0][0][0][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pjQjFUsv-2rL",
        "outputId": "56df56c5-413d-42b5-a8d0-7f6717101478"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[0.0290, 0.4019, 0.2598],\n",
            "         [0.3666, 0.0583, 0.7006],\n",
            "         [0.0518, 0.4681, 0.6738]],\n",
            "\n",
            "        [[0.3315, 0.7837, 0.5631],\n",
            "         [0.7749, 0.8208, 0.2793],\n",
            "         [0.6817, 0.2837, 0.6567]]])\n",
            "tensor([[0.0290, 0.4019, 0.2598],\n",
            "        [0.3666, 0.0583, 0.7006],\n",
            "        [0.0518, 0.4681, 0.6738]])\n",
            "tensor([0.0290, 0.4019, 0.2598])\n",
            "tensor(0.0290)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Remark .** In many neural networks random tensors are very important because they often learn by strating with a random tensor and updating it adjusting the values to better represent or fit the data."
      ],
      "metadata": {
        "id": "BpAb_7v1_dsS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tensor-range (default start=0, end=length-1, step=1)\n",
        "range = torch.arange(start=0,end=10,step=2)\n",
        "print(range)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_4Q2Z0iDL51",
        "outputId": "6712a44c-17f4-42d9-be91-b1aa15207712"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 2, 4, 6, 8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating tensors like the previous one but with all zeros\n",
        "tensor_like = torch.zeros_like(input=range)\n",
        "print(tensor_like)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pqgKjx41Dwzb",
        "outputId": "516007bd-c186-4040-ca52-55d1aebd4b98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 0, 0, 0, 0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Slicing and reshaping\n",
        "Slicing is very similar to the same operation with python arrays, and reshaping can be done with the function `torch.tensor.view()`, see https://pytorch.org/docs/stable/generated/torch.Tensor.view.html."
      ],
      "metadata": {
        "id": "ekP6mwS7LGzX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Slicing\n",
        "x = torch.rand(4,4)\n",
        "print(x)\n",
        "print(x[:,0])\n",
        "print(x[0,0])\n",
        "print(x[1,1].item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yzQjTtLHLJi4",
        "outputId": "99bc006f-5b2a-445d-ba16-fef0b7f67ce7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.2388, 0.7313, 0.6012, 0.3043],\n",
            "        [0.2548, 0.6294, 0.9665, 0.7399],\n",
            "        [0.4517, 0.4757, 0.7842, 0.1525],\n",
            "        [0.6662, 0.3343, 0.7893, 0.3216]])\n",
            "tensor([0.2388, 0.2548, 0.4517, 0.6662])\n",
            "tensor(0.2388)\n",
            "0.6293618679046631\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshaping\n",
        "print(x.size())\n",
        "\n",
        "y = x.view(16)\n",
        "print(y)\n",
        "print(y.size())\n",
        "\n",
        "y = x.view(-1,8)\n",
        "print(y)\n",
        "print(y.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k4Zm57CRLan1",
        "outputId": "d073720a-0233-44c3-9846-290f877b40a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 4])\n",
            "tensor([0.2388, 0.7313, 0.6012, 0.3043, 0.2548, 0.6294, 0.9665, 0.7399, 0.4517,\n",
            "        0.4757, 0.7842, 0.1525, 0.6662, 0.3343, 0.7893, 0.3216])\n",
            "torch.Size([16])\n",
            "tensor([[0.2388, 0.7313, 0.6012, 0.3043, 0.2548, 0.6294, 0.9665, 0.7399],\n",
            "        [0.4517, 0.4757, 0.7842, 0.1525, 0.6662, 0.3343, 0.7893, 0.3216]])\n",
            "torch.Size([2, 8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Aritmetic operations with tensors\n",
        "Aritmetic operations between tensors are very similar to aritmetic operations with arrays (e.g. in `numpy`)"
      ],
      "metadata": {
        "id": "CFuXC4IoAiiA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Elementwise addition of tensors with the same size\n",
        "a = torch.rand(2,2)\n",
        "b = torch.rand(2,2)\n",
        "c = a+b\n",
        "print(a)\n",
        "print(b)\n",
        "print(c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ytfA5fuLAkwV",
        "outputId": "6637a3c6-4f2b-406e-da0e-15a431ab7fa5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.5247, 0.6688],\n",
            "        [0.8436, 0.4265]])\n",
            "tensor([[0.9561, 0.0770],\n",
            "        [0.4108, 0.0014]])\n",
            "tensor([[1.4809, 0.7458],\n",
            "        [1.2544, 0.4279]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# same as before\n",
        "print(torch.add(a,b))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YvGeTaibAwCX",
        "outputId": "f108c99c-881a-4730-de4b-25cf0f074590"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.4809, 0.7458],\n",
            "        [1.2544, 0.4279]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# inplace addition, same as before\n",
        "# all pytorch function with _ at the end are usually inplace operations\n",
        "print(b.add_(a))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JTSOWWcgBeaH",
        "outputId": "4ff0678c-2a44-4d3f-e4c9-7dd78cdc7de3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.4809, 0.7458],\n",
            "        [1.2544, 0.4279]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "All the other aritmetic operations are carried out in a similar fashion. In particular we have:\n",
        "\n",
        "\n",
        "*   **elementwise subtraction** `a-b` or `torch.sub(a,b)` or `a.sub_(b)`;\n",
        "*   **elementwise multiplication** `a*b` or `torch.mul(a,b)` or `a.mul_(b)`;\n",
        "*   **elementwise division** ` a / b ` or `torch.div(a,b)` or `a.div_(b)`;\n",
        "*   **elementwise power** ` a**b ` or `torch.pow(a,b)` or `a.pow_(b)`;\n",
        "\n",
        "See https://pytorch.org/docs/stable/torch.html for all the other useful operations."
      ],
      "metadata": {
        "id": "oOxssJYlBko2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Remark .** The device where a tensor is saved is of crucial importance as the following code shows."
      ],
      "metadata": {
        "id": "QTXQHdu_G_Ov"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tensor \n",
        "x = torch.ones(5)\n",
        "print(x)\n",
        "# Move it in the GPU\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda\")\n",
        "  x = x.to(device)\n",
        "  print(x)\n",
        "\n",
        "# Move the tensor in the CPU\n",
        "x = x.to(\"cpu\")\n",
        "# Change the tensor in the CPU\n",
        "# Note that x+=1 is the same as x=x+1\n",
        "x += 1\n",
        "print(x)\n",
        "\n",
        "# Also the tensor in the GPU has been changed!\n",
        "if torch.cuda.is_available():\n",
        "  x = x.to(device)\n",
        "  print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ponHvQxtHn3M",
        "outputId": "f8ff5c1e-3740-4978-b121-54efba69df9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 1., 1., 1., 1.])\n",
            "tensor([1., 1., 1., 1., 1.], device='cuda:0')\n",
            "tensor([2., 2., 2., 2., 2.])\n",
            "tensor([2., 2., 2., 2., 2.], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## From Numpy to PyThorch and back\n",
        "Many operations between tensors (e.g. matrix multiplications) are particularly easy to carry out with `numpy`, see https://numpy.org. To convert a tensor to a numpy array, and vicerversa, we can use the following code. "
      ],
      "metadata": {
        "id": "w2hb3HekKIRS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "WFY1WjBbKicT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.ones(5)\n",
        "print(a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gBQKgMR5KlkK",
        "outputId": "341559b4-a73d-4b3a-9cba-f25d71ba8f3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 1., 1., 1., 1.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# From PyThorch to Numpy\n",
        "b = a.numpy()\n",
        "print(b)\n",
        "print(type(b))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NcxD0LSUKqGU",
        "outputId": "fdbb3b81-6acf-4555-f5ed-b5a8e11eb859"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1. 1. 1. 1. 1.]\n",
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# From Numpy to PyThorch\n",
        "a = np.ones(5)\n",
        "b = torch.from_numpy(a)\n",
        "print(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_bzruukKtCu",
        "outputId": "1e091acf-9f55-482c-b74b-bdffee6bf4ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Remark .** At the time of writing `numpy` works only with CPUs. "
      ],
      "metadata": {
        "id": "wDeBLLGUK0Xc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercises\n",
        "\n",
        "\n",
        "1.   Create a random tensor `a` with shape (4,4) and perform a matrix multiplication with another random tensor `b` with shape (1, 4) (hint: you may have to transpose the second tensor).\n",
        "2.   Find the maximum and minimum values of the output of the matrix multiplication of `a` and `b` created in the previous exercise.\n",
        "3.   Speaking of random seeds, we saw how to set it with torch.manual_seed() but is there a GPU equivalent? (hint: look into the documentation for `torch.cuda` for this one). \n",
        "\n"
      ],
      "metadata": {
        "id": "MB7V_n0XO4iq"
      }
    }
  ]
}